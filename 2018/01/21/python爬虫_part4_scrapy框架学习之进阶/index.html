<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>python爬虫_part4_scrapy框架学习之进阶 | ljming的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="学习 scrapy 基本命令之后，开始学习 scrapy 的高级用法。包括如何机构化你爬取的数据, 怎样编写你的 spider 文件, spider 的一些属性和方法, xpath 的基础以及怎样进行传递参数运行 spider 文件。">
<meta name="keywords" content="爬虫,scrapy">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫_part4_scrapy框架学习之进阶">
<meta property="og:url" content="https://ljm516.github.io/2018/01/21/python爬虫_part4_scrapy框架学习之进阶/index.html">
<meta property="og:site_name" content="ljming的博客">
<meta property="og:description" content="学习 scrapy 基本命令之后，开始学习 scrapy 的高级用法。包括如何机构化你爬取的数据, 怎样编写你的 spider 文件, spider 的一些属性和方法, xpath 的基础以及怎样进行传递参数运行 spider 文件。">
<meta property="og:locale" content="zh">
<meta property="og:updated_time" content="2018-11-05T15:22:52.621Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python爬虫_part4_scrapy框架学习之进阶">
<meta name="twitter:description" content="学习 scrapy 基本命令之后，开始学习 scrapy 的高级用法。包括如何机构化你爬取的数据, 怎样编写你的 spider 文件, spider 的一些属性和方法, xpath 的基础以及怎样进行传递参数运行 spider 文件。">
  
    <link rel="alternate" href="/atom.xml" title="ljming的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">ljming的博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">程序人生</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://ljm516.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-python爬虫_part4_scrapy框架学习之进阶" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/21/python爬虫_part4_scrapy框架学习之进阶/" class="article-date">
  <time datetime="2018-01-21T14:00:00.000Z" itemprop="datePublished">2018-01-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/python/">python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      python爬虫_part4_scrapy框架学习之进阶
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>学习 scrapy 基本命令之后，开始学习 scrapy 的高级用法。包括如何机构化你爬取的数据, 怎样编写你的 spider 文件, spider 的一些属性和方法, xpath 的基础以及怎样进行传递参数运行 spider 文件。 </p>
<a id="more"></a>
<h3 id="scrapy-进阶"><a href="#scrapy-进阶" class="headerlink" title="scrapy 进阶"></a>scrapy 进阶</h3><ul>
<li>items.py: 存储爬取的数据，将非结构化数据转成结构化数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">person</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line"><span class="meta">... </span>    name = scrapy.Field()</span><br><span class="line"><span class="meta">... </span>    job = scrapy.Field()</span><br><span class="line"><span class="meta">... </span>    email = scrapy.Field()</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ljm = person(name=<span class="string">'ljming'</span>, job=<span class="string">'coder'</span>, email=<span class="string">'xxxxxxx@qq.com'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(ljm)</span><br><span class="line">&#123;<span class="string">'email'</span>: <span class="string">'xxxxxxx@qq.com'</span>, <span class="string">'job'</span>: <span class="string">'coder'</span>, <span class="string">'name'</span>: <span class="string">'ljming'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(ljm.keys())</span><br><span class="line">dict_keys([<span class="string">'name'</span>, <span class="string">'job'</span>, <span class="string">'email'</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(ljm.items())</span><br><span class="line">ItemsView(&#123;<span class="string">'email'</span>: <span class="string">'xxxxxxx@qq.com'</span>, <span class="string">'job'</span>: <span class="string">'coder'</span>, <span class="string">'name'</span>: <span class="string">'ljming'</span>&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>Spider 的编写</li>
</ul>
<p>在项目中可以使用 genspider 命令创建一个爬虫文件，然后我们对它来进行修改。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LjmSpider</span><span class="params">(scrapy.Spider)</span>:</span>  <span class="comment"># 继承 scrapy.Spider</span></span><br><span class="line">    name = <span class="string">'ljm'</span>  <span class="comment"># 代表爬虫名称</span></span><br><span class="line">    allowed_domains = [<span class="string">'baidu.com'</span>]  <span class="comment"># 表示允许爬取的域名</span></span><br><span class="line">    start_urls = [<span class="string">'http://baidu.com/'</span>]  <span class="comment"># 表示开始爬取的网址</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    parse 方法，如果没有特别指定回调函数，该方法是处理 Scrapy </span></span><br><span class="line"><span class="string">    爬虫爬行到的网页响应的默认方法。通过该方法可以e对响应进行</span></span><br><span class="line"><span class="string">    处理并返回处理后的数据，同时该方法也负责链接的跟进。</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<ul>
<li>spider 的其它一些属性和方法</li>
</ul>
<table>
<thead>
<tr>
<th>名称</th>
<th>属性 or 方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>start_requests()</td>
<td>方法</td>
<td>该方法会默认读取 start_urls 属性（当然可以是自定义）中定义的网址，为每一个网址生成一个 Request 请求对象，并返回可迭代对象。</td>
</tr>
<tr>
<td>make_requests_from_url(url)</td>
<td>方法</td>
<td>该方法会被 start_requests() 调用，该方法负责实现生成 Request 请求对象</td>
</tr>
<tr>
<td>closed(reason)</td>
<td>方法</td>
<td>关闭 Spider时， 该方法会被调用</td>
</tr>
<tr>
<td>log(message[, level, component])</td>
<td>方法</td>
<td>使用该方法可以实现在 Spider 中添加 log</td>
</tr>
<tr>
<td><strong>init</strong>()</td>
<td>方法</td>
<td>该方法主要负责爬虫的初始化，为构造函数</td>
</tr>
</tbody>
</table>
<h5 id="items-py"><a href="#items-py" class="headerlink" title="items.py"></a>items.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScrapylearnItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpiderItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">	url_name = scrapy.Field()</span><br><span class="line">	url_key = scrapy.Field()</span><br><span class="line">	url_cr = scrapy.Field()</span><br><span class="line">	url_addr = scrapy.Field()</span><br></pre></td></tr></table></figure>
<h5 id="ljm-py"><a href="#ljm-py" class="headerlink" title="ljm.py"></a>ljm.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapyLearn.items <span class="keyword">import</span> MySpiderItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LjmSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'ljm'</span></span><br><span class="line">    allowed_domains = [<span class="string">'baidu.com'</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_15501735110847759526%22%7D&amp;n_type=0&amp;p_from=1'</span>,</span><br><span class="line">        <span class="string">'https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_17413885825184600007%22%7D&amp;n_type=0&amp;p_from=1'</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = MySpiderItem()</span><br><span class="line">        <span class="comment"># print(response.text)</span></span><br><span class="line">        item[<span class="string">'url_name'</span>] = response.xpath(<span class="string">"/html/head/title/text()"</span>)</span><br><span class="line">        print(<span class="string">'url_name:'</span>, item[<span class="string">'url_name'</span>])</span><br></pre></td></tr></table></figure>
<p>执行 <code>scrapy crawl [spider_name]</code> 运行此程序</p>
<h3 id="XPath-基础"><a href="#XPath-基础" class="headerlink" title="XPath 基础"></a>XPath 基础</h3><p>XPath 是一种 XML 路径语言， 通过改语言可以再 XML 文档中迅速地查找到相应的信息。 XPath 表达式通常叫做 XPath selector。</p>
<p>想获取标签中的文本信息，可以通过 text() 实现。例如：<code>/html/body/h2/text()</code></p>
<p>可以使用 <code>//</code> 提取某个标签的所有信息。例如：<code>//p</code></p>
<p>如果想获取所有属性 <code>X</code> 的值为 <code>Y</code> 的 <code>&lt;Z&gt;</code> 标签的内容，可以通过 <code>//Z[@X=&#39;Y&#39;]</code> 的方式获取。 例如： <code>//img[@class=&#39;f1&#39;]</code></p>
<h3 id="Spider-类参数传递"><a href="#Spider-类参数传递" class="headerlink" title="Spider 类参数传递"></a>Spider 类参数传递</h3><p>在 Spider 类中可以通过 <code>-a</code> 选项实现参数的传递。</p>
<p>首先，在 Spider 文件中重写 <code>__init__</code> 方法, 在构造方法中设置一个变量用于接受用户在执行爬虫文件时传递过来的参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapyLearn.items <span class="keyword">import</span> MySpiderItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LjmSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'ljm'</span></span><br><span class="line">    allowed_domains = [<span class="string">'baidu.com'</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_15501735110847759526%22%7D&amp;n_type=0&amp;p_from=1'</span>,</span><br><span class="line">        <span class="string">'https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_17413885825184600007%22%7D&amp;n_type=0&amp;p_from=1'</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实现参数传递</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, myurl=None, *args, **kwargs)</span>:</span></span><br><span class="line">        super(LjmSpider, self).__init__(*args, **kwargs)</span><br><span class="line">        print(<span class="string">'要爬取的网页地址: '</span>, myurl)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 重新定义 start_urls 属性，属性值为传进来的参数值</span></span><br><span class="line">        self.start_urls = [myurl]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = MySpiderItem()</span><br><span class="line">        item[<span class="string">'url_name'</span>] = response.xpath(<span class="string">"/html/head/title/text()"</span>)</span><br><span class="line">        print(<span class="string">'url_name:'</span>, item[<span class="string">'url_name'</span>])</span><br></pre></td></tr></table></figure>
<p>运行： <code>scrapy crawl ljm -a myurl=http://www.baidu.com</code></p>
<p><strong>如要传递多个url， 可以使用某个符号将每个url分隔，然后再后台接收后，使用 split 方法进行分隔</strong></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://ljm516.github.io/2018/01/21/python爬虫_part4_scrapy框架学习之进阶/" data-id="cjsmuf3xd000u0jfy0e5ebjll" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/">scrapy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/01/31/python-small-skills/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          python 中的一些小技巧合集
        
      </div>
    </a>
  
  
    <a href="/2018/01/16/python-excel/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">python 处理 execl 文件</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/BigData/">BigData</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/消息队列/">消息队列</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/经历/">经历</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/JVM/">JVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL/">MySQL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ORM/">ORM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RocketMQ/">RocketMQ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/broker/">broker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/consumer/">consumer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/maven/">maven</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/producer/">producer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrapy/">scrapy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/设计模式/">设计模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试/">面试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试题/">面试题</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/JVM/" style="font-size: 12.5px;">JVM</a> <a href="/tags/MySQL/" style="font-size: 12.5px;">MySQL</a> <a href="/tags/ORM/" style="font-size: 10px;">ORM</a> <a href="/tags/RocketMQ/" style="font-size: 15px;">RocketMQ</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/broker/" style="font-size: 10px;">broker</a> <a href="/tags/consumer/" style="font-size: 10px;">consumer</a> <a href="/tags/maven/" style="font-size: 10px;">maven</a> <a href="/tags/producer/" style="font-size: 10px;">producer</a> <a href="/tags/redis/" style="font-size: 10px;">redis</a> <a href="/tags/scrapy/" style="font-size: 17.5px;">scrapy</a> <a href="/tags/爬虫/" style="font-size: 20px;">爬虫</a> <a href="/tags/设计模式/" style="font-size: 12.5px;">设计模式</a> <a href="/tags/面试/" style="font-size: 10px;">面试</a> <a href="/tags/面试题/" style="font-size: 10px;">面试题</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/02/24/Java垃圾收集/">Java垃圾收集</a>
          </li>
        
          <li>
            <a href="/2019/02/24/Java运行时数据区域/">Java运行时数据区域</a>
          </li>
        
          <li>
            <a href="/2019/01/06/rocketmq之consumer消息消费者/">rocketmq之consumer消息消费者</a>
          </li>
        
          <li>
            <a href="/2019/01/03/rocketmq之producer消息发送者/">rocketmq之producer消息发送者</a>
          </li>
        
          <li>
            <a href="/2018/12/28/rocketmq之broker源码学习/">rocketmq之broker源码学习</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 lijianmging<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>