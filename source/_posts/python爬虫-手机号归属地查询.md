---
title: pythonçˆ¬è™«-æ‰‹æœºå·å½’å±åœ°æŸ¥è¯¢
date: 2019-05-18 17:53:10
categories: Python
tags:
- çˆ¬è™«
---

å¥½ä¹…æ²¡æœ‰å†™pythonçš„è®°å½•ï¼Œå‰ä¸¤å¤©å·¥ä½œåŸå› ï¼Œéœ€è¦æ ¹æ®æ‰‹æœºå·å‰7ä½çˆ¬å–æ‰‹æœºå·å½’å±åœ°ä»¥åŠè¿è¥å•†çš„ä¿¡æ¯ï¼Œäºæ˜¯å†™äº†ä¸ªçˆ¬è™«è„šæœ¬ã€‚åŸå…ˆåªæ˜¯ä½¿ç”¨requestsåº“ï¼Œè¿›è¡Œäº†å•çº¿ç¨‹çš„çˆ¬å–ï¼Œå‘ç°å¤ªæ…¢äº†ï¼Œè€Œä¸”ä¼šå‡ºç°åœé¡¿è·å–ä¸åˆ°ç»“æœçš„é—®é¢˜ï¼Œåé¢æœæ–­ä½¿ç”¨äº†scrapyæ¡†æ¶ï¼Œé‚£æ˜¯ç›¸å½“çš„å¿«ï¼ŒğŸ‘ã€‚

<!--more-->

## åŸºäºrequests
åˆ›å»ºäº†ä¸€ä¸ªpythonæ–‡ä»¶å¤¹ï¼Œç„¶ååˆ›å»ºäº†ä¸¤ä¸ªpythonæ–‡ä»¶ï¼Œrun.py, spider.pyã€‚å‰è€…æ˜¯ç¨‹åºè¿è¡Œçš„å…¥å£ï¼Œåè€…è¿›è¡Œæ•°æ®çˆ¬å–ã€‚

- run.py
![run.py](runpy.png)
- spider.py
![spider.py](spiderpy.png)

`requests.get(url)`å°±æ˜¯è¯·æ±‚urlï¼Œç„¶åè¿”å›ç»“æœã€‚éœ€è¦è§‚å¯Ÿresponseçš„å†…å®¹ï¼Œç„¶åå¯¹å†…å®¹è§£æï¼Œæƒ³è¿™ä¸ªå“åº”å†…å®¹å°±æ˜¯ä¸€ä¸ªjsonæ ¼å¼æ•°æ®ï¼Œé‚£ä¹ˆå°±ç”¨jsonåº“åºåˆ—åŒ–ï¼Œå°±å¯ä»¥è½»æ¾åœ°å–å‡ºæƒ³è¦çš„æ•°æ®ã€‚for å¾ªåæ˜¯ä¸ºäº†å¦‚æœå“åº”ç ä¸ä¸º200ï¼Œè¿›è¡Œçš„é‡è¯•ç­–ç•¥ã€‚timeoutè®¾ç½®æœ€å¤§ç­‰å¾…æ—¶é—´ã€‚

å»ºè®®: å­—ç¬¦ä¸²çš„æ‹¼æ¥ä¸è¦ç”¨`+`ï¼Œpythonä¸­å­—ç¬¦ä¸²å’Œæ•°å­—æ˜¯ä¸èƒ½ç”¨`+`æ‹¼æ¥çš„ï¼Œé™¤éå°†æ•°å­—è½¬æ¢æˆå­—ç¬¦ä¸²ã€‚ä½œä¸ºä»£æ›¿ï¼Œå¯ä»¥ä½¿ç”¨format()æ–¹æ³•ï¼Œä¾‹å¦‚:
```python
'ljming{}'.format(666);
```
å¦‚æœè¦æ‹¼æ¥å¤šä¸ªå­—ç¬¦ä¸²ï¼Œå¯ä»¥åœ¨å¤§æ‹¬å·é‡Œè®¾ç½®ä¸€ä¸ªæ ‡è¯†ï¼Œåœ¨formatå‡½æ•°é‡Œä¸ºè¿™ä¸ªæ ‡è¯†èµ‹å€¼ã€‚
```python
'ljming{age},{address}'.format(age=18, address=beijing)
```

## ä½¿ç”¨scrapy

é¦–å…ˆæ˜¯æœ‰ä¸ªscrapyå‘½ä»¤æ–°å»ºä¸€ä¸ªscrapyé¡¹ç›®`scrapy startproject [projectName]`ï¼Œç„¶ååœ¨ä½ çš„è¿è¡Œå‘½ä»¤çš„é‚£ä¸ªç›®å½•å°±ä¼šç”Ÿæˆä¸€ä¸ªprojectNameçš„æ–‡ä»¶å¤¹ã€‚

![scrapy-start-project](startproject.png)

æ–‡ä»¶å¤¹é‡Œçš„æ¯ä¸ªæ–‡ä»¶æ˜¯å¹²å˜›çš„ï¼Œå¯ä»¥è‡ªè¡Œç™¾åº¦ã€‚

ç„¶åé€šè¿‡å‘½ä»¤ `scrapy genspider -t basic [spiderName]`ç”Ÿæˆä¸€ä¸ªspideræ–‡ä»¶ã€‚scrapyå‘½ä»¤å¯ä»¥çœ‹ **{% post_link pythonçˆ¬è™«_part3_scrapyå­¦ä¹ ä¹‹å…¥é—¨ pythonçˆ¬è™«_part3_scrapyå­¦ä¹ ä¹‹å…¥é—¨ %}**

- python_spider.py

```python
class PhoneSpiderSpider(scrapy.Spider):
    name = 'phone_spider'
    allowed_domains = ['mobsec-dianhua.baidu.com']
    base_url = "http://mobsec-dianhua.baidu.com/dianhua_api/open/location?tel={}"
    start_urls = []

    def __init__(self, *args, **kwargs):
        super(PhoneSpiderSpider, self).__init__(*args, **kwargs)
        phone_head = [1480000, 1650000, 1670000, 1910000, 1620000, 1700000, 1710000]

        for head in phone_head:
            stop_flag = head + 9999
            while head <= stop_flag:
                self.start_urls.append(self.base_url.format(head))
                head += 1

        print("start_urls size={}".format(len(self.start_urls)))

    def parse(self, response):
        rsp_content = response.text
        json_obj = json.loads(rsp_content)

        data_json = json_obj['response']
        rsp_header = json_obj['responseHeader']
        if rsp_header['status'] != 200:
            print("response not success")

        request_phone = response.url.split('=')[1]
        print('request_phone={}'.format(request_phone))

        item = PhoneInfoItem()
        item['phone'] = request_phone
        item['head'] = request_phone[:3]
        if data_json[str(request_phone)] is not None and data_json[request_phone]['detail'] is not None:
            item['operator'] = data_json[request_phone]['detail']['operator']
            item['province'] = data_json[request_phone]['detail']['province']
            item['city'] = data_json[request_phone]['detail']['area'][0]['city']

            print("item={}".format(item))
        else:
            item['operator'] = ''
            item['province'] = ''
            item['city'] = ''

        yield item
```

`__init__` å‡½æ•°å¯¹PhoneSpiderSpiderè¿›è¡Œåˆå§‹åŒ–ï¼Œä¸»è¦æ˜¯åˆ›å»ºäº†éœ€è¦çˆ¬å»çš„å·ç ï¼Œç„¶åå°†å·ç æ”¾è¿›start_ulsé›†åˆä¸­ã€‚

`parse` å‡½æ•°æ˜¯å°±å“åº”ç»“æœè¿›è¡Œå¤„ç†ï¼Œä¸»è¦æ˜¯è§‚å¯Ÿreponseçš„å†…å®¹æ ¼å¼ï¼Œç„¶åè¿›è¡Œå¤„ç†ã€‚`PhoneInfoItem`è¿™ä¸ªç±»æ˜¯`item.py`çš„ä¸€ä¸ªç±»ï¼Œæ˜¯strat projectå‘½ä»¤è‡ªåŠ¨ç”Ÿæˆçš„ã€‚å¯ä»¥æ ¹æ®å…·ä½“æƒ…å†µï¼Œè®¾ç½®å±æ€§ã€‚

- item.py

```python
class PhoneInfoItem(scrapy.Item):
    # define the fields for your item here like:
    # name = scrapy.Field()
    phone = scrapy.Field()
    head = scrapy.Field()
    province = scrapy.Field()
    city = scrapy.Field()
    operator = scrapy.Field()
```

åœ¨parseå‡½æ•°ä¸­ï¼Œå–å‡ºè¦çš„å€¼ï¼Œç„¶åå®ä¾‹åŒ–PhoneInfoItemç±»ï¼Œæœ€å yield itemã€‚yield itemä¹‹åpipelines.pyå°±ä¼šå¯¹itemè¿›è¡Œå¤„ç†ï¼Œè¿™é‡Œä¸€èˆ¬æ˜¯å°†ä¿å­˜æ•°æ®çš„æ“ä½œï¼ˆå†™æ–‡ä»¶oræ•°æ®åº“ï¼‰ã€‚

è¿™é‡Œéœ€è¦æ‰“å¼€`settings.py`æ–‡ä»¶çš„ä¸€ä¸ªæ³¨é‡Š
![item_pipelines](itempipelines.png)

- settings.py
è¯¥æ–‡ä»¶å†…å®¹ä¸»è¦æ˜¯å¯¹ä½ çš„çˆ¬è™«è¿›è¡Œä¸€äº›è®¾ç½®ï¼Œé»˜è®¤æ‰€æœ‰çš„é…ç½®éƒ½æ˜¯è¢«æ³¨é‡Šæ‰çš„ï¼Œå¦‚æœè¦ç”¨æ‰“å¼€å°±è¡Œã€‚

- pipelines.py

```python
MYSQL_HOST = '127.0.0.1'
MYSQL_PORT = 3306
MYSQL_USER = 'ljm'
MYSQL_PASSWD = ''
MYSQL_DB = 'spider'

db = MySQLDatabase(MYSQL_DB, host=MYSQL_HOST, port=MYSQL_PORT, user=MYSQL_USER, passwd=MYSQL_PASSWD)


class BaseModel(Model):
    class Meta:
        database = db


class Phone_Info(BaseModel):
    id = PrimaryKeyField()
    number = CharField()
    head = CharField()
    province = CharField()
    city = CharField()
    operator = CharField()


class PhoneInfoPipeline(object):

    def process_item(self, item, spider):
        phone_info = Phone_Info(number=item['phone'], operator=item['operator'],
                                head=item['head'], province=item['province'], city=item['city'])
        phone_info.save()
        return item

```
pipelines.py ç”Ÿæˆæ—¶åªæœ‰ PhoneInfoPipelineè¿™ä¸ªç±»ï¼Œä¸Šé¢çš„æ˜¯ä¸ºäº†æ•°æ®å…¥åº“ç”¨çš„ï¼Œè¿™é‡Œç”¨åˆ°äº†pythonçš„ä¸€ä¸ªormæ¡†æ¶-peeweeï¼Œæ€ä¹ˆç”¨ï¼Ÿçœ‹**{% post_link peeweeå…¥é—¨ peeweeå…¥é—¨ %}**ã€‚

`process_item`å‡½æ•°å°±æ˜¯å…·ä½“å¤„ç†æ•°æ®çš„å‡½æ•°ï¼Œæœ€ç»ˆé€šè¿‡peeweeä¿å­˜åœ¨æ•°æ®åº“ã€‚